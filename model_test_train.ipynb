{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8122823c",
   "metadata": {},
   "source": [
    "## Testing a model for a Kaggle challenge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "232c7346",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[LightGBM] [Info] Total Bins 768\n",
      "[LightGBM] [Info] Number of data points in the train set: 240000, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 85.475452\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import lightgbm as lgb\n",
    "\n",
    "\n",
    "df = pd.read_csv('./train.csv')\n",
    "\n",
    "features = ['f0', 'f1', 'f2', 'region']\n",
    "\n",
    "X = df[features]\n",
    "y = df['product']\n",
    "\n",
    "lgbm_reg = lgb.LGBMRegressor(random_state=42,\n",
    "                             n_estimators=250,\n",
    "                             learning_rate=0.05,\n",
    "                             num_leaves=32,\n",
    "                             max_depth=-1,\n",
    "                             reg_alpha=0.1,\n",
    "                             reg_lambda=0.1,\n",
    "                             force_col_wise=True)\n",
    "\n",
    "lgbm_reg.fit(X, y)\n",
    "\n",
    "test = pd.read_csv('./test.csv')\n",
    "test['product'] = lgbm_reg.predict(test[features])\n",
    "test[['id', 'product']].to_csv('answer.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "912f0f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Formato de X_train: (192000, 4)\n",
      "Formato de X_test: (48000, 4)\n",
      "\n",
      "Iniciando o ajuste de hiperparâmetros para LGBMRegressor com GridSearchCV...\n",
      "Fitting 3 folds for each of 3 candidates, totalling 9 fits\n",
      "[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.001876 seconds.\n",
      "You can set `force_row_wise=true` to remove the overhead.\n",
      "And if memory is not enough, you can set `force_col_wise=true`.\n",
      "[LightGBM] [Info] Total Bins 768\n",
      "[LightGBM] [Info] Number of data points in the train set: 192000, number of used features: 4\n",
      "[LightGBM] [Info] Start training from score 85.464094\n",
      "\n",
      "Ajuste de hiperparâmetros concluído.\n",
      "Melhores parâmetros encontrados: {'learning_rate': 0.05, 'max_depth': -1, 'n_estimators': 250, 'num_leaves': 32, 'reg_alpha': 0.1, 'reg_lambda': 0.1}\n",
      "Melhor pontuação (neg_mean_squared_error) na validação cruzada: 0.5690\n",
      "\n",
      "--- Avaliação do Melhor LGBMRegressor (após GridSearchCV) ---\n",
      "Mean Squared Error (MSE): 934.3355\n",
      "Root Mean Squared Error (RMSE): 30.5669\n",
      "Mean Absolute Error (MAE): 20.9580\n",
      "R-squared (R2): 0.5628\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "import lightgbm as lgb # Certifique-se de que esta biblioteca está instalada\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
    "import numpy as np\n",
    "\n",
    "# Carregar o dataset\n",
    "file_path = './train.csv' # Use o nome correto do seu arquivo\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "\n",
    "    # --- Engenharia e Seleção de Features ---\n",
    "    if 'product' not in df.columns:\n",
    "        print(\"Erro: Coluna 'product' não encontrada.\")\n",
    "        raise ValueError(\"Coluna alvo 'product' não encontrada.\")\n",
    "\n",
    "    if df['product'].dtype != 'float64' and df['product'].dtype != 'int64':\n",
    "        print(f\"Aviso: A coluna 'product' é do tipo {df['product'].dtype}. Para regressão, deve ser numérica.\")\n",
    "        df['product'] = pd.to_numeric(df['product'], errors='coerce')\n",
    "        if df['product'].isnull().any():\n",
    "            print(\"Aviso: Valores de 'product' que não puderam ser convertidos para numérico (NaN) foram removidos.\")\n",
    "            df.dropna(subset=['product'], inplace=True)\n",
    "            if df.empty:\n",
    "                raise ValueError(\"O DataFrame ficou vazio após remover valores NaN da coluna 'product'.\")\n",
    "\n",
    "    features = ['f0', 'f1', 'f2', 'region']\n",
    "    missing_features = [col for col in features if col not in df.columns]\n",
    "    if missing_features:\n",
    "        print(f\"Erro: As seguintes colunas de features estão faltando: {missing_features}\")\n",
    "        raise ValueError(f\"Colunas de features faltando: {missing_features}\")\n",
    "\n",
    "    X = df[features]\n",
    "    y = df['product']\n",
    "\n",
    "    if X.empty or y.empty:\n",
    "         raise ValueError(\"Features (X) ou alvo (y) estão vazios antes da divisão.\")\n",
    "\n",
    "    # --- Divisão dos Dados ---\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    print(f\"Formato de X_train: {X_train.shape}\")\n",
    "    print(f\"Formato de X_test: {X_test.shape}\")\n",
    "\n",
    "    if X_train.empty or y_train.empty:\n",
    "        raise ValueError(\"Dados de treino (X_train ou y_train) estão vazios.\")\n",
    "\n",
    "    # --- Ajuste de Hiperparâmetros com GridSearchCV ---\n",
    "    print(\"\\nIniciando o ajuste de hiperparâmetros para LGBMRegressor com GridSearchCV...\")\n",
    "\n",
    "    # Define o estimador\n",
    "    estimator = lgb.LGBMRegressor(random_state=42)\n",
    "\n",
    "    # Define a grade de parâmetros para testar\n",
    "    # Esta é uma grade pequena para demonstração. Você pode expandi-la.\n",
    "    param_grid = {\n",
    "        'n_estimators': [260, 270, 280],\n",
    "        'learning_rate': [0.04, 0.05, 0.06],\n",
    "        'num_leaves': [30, 31, 32], # Padrão é 31\n",
    "        'max_depth': [-1, 10, 20], # -1 significa sem limite\n",
    "        'reg_alpha': [0, 0.1, 0.5],\n",
    "        'reg_lambda': [0, 0.1, 0.5]\n",
    "    }\n",
    "\n",
    "    # Configura o GridSearchCV\n",
    "    # 'neg_mean_squared_error' é usado porque GridSearchCV tenta maximizar a pontuação,\n",
    "    # então usamos o MSE negativo. Outras opções: 'r2'.\n",
    "    # cv=3 significa validação cruzada de 3 folds. Aumente se tiver poder computacional.\n",
    "    # n_jobs=-1 usa todos os processadores disponíveis.\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=estimator,\n",
    "        param_grid=param_grid,\n",
    "        scoring='r2',\n",
    "        cv=3,\n",
    "        verbose=1, # Mostra o progresso\n",
    "        n_jobs=-1 # Use -1 para usar todos os processadores, ou 1 se causar problemas\n",
    "    )\n",
    "\n",
    "    # Executa a busca em grade\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    print(\"\\nAjuste de hiperparâmetros concluído.\")\n",
    "    print(f\"Melhores parâmetros encontrados: {grid_search.best_params_}\")\n",
    "    print(f\"Melhor pontuação (neg_mean_squared_error) na validação cruzada: {grid_search.best_score_:.4f}\")\n",
    "\n",
    "    # Pega o melhor estimador encontrado pelo GridSearchCV\n",
    "    best_lgbm_reg = grid_search.best_estimator_\n",
    "\n",
    "    # --- Predições com o Melhor Modelo ---\n",
    "    y_pred_best_lgbm = best_lgbm_reg.predict(X_test)\n",
    "\n",
    "    # --- Avaliação do Melhor Modelo ---\n",
    "    print(\"\\n--- Avaliação do Melhor LGBMRegressor (após GridSearchCV) ---\")\n",
    "    mse = mean_squared_error(y_test, y_pred_best_lgbm)\n",
    "    rmse = np.sqrt(mse)\n",
    "    mae = mean_absolute_error(y_test, y_pred_best_lgbm)\n",
    "    r2 = r2_score(y_test, y_pred_best_lgbm)\n",
    "\n",
    "    print(f\"Mean Squared Error (MSE): {mse:.4f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE): {rmse:.4f}\")\n",
    "    print(f\"Mean Absolute Error (MAE): {mae:.4f}\")\n",
    "    print(f\"R-squared (R2): {r2:.4f}\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Erro: O arquivo '{file_path}' não foi encontrado.\")\n",
    "except ValueError as ve:\n",
    "    print(f\"ValueError: {ve}\")\n",
    "except Exception as e:\n",
    "    print(f\"Um erro inesperado ocorreu: {e}\")\n",
    "    import traceback\n",
    "    print(traceback.format_exc())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
